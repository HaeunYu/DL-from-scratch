{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어 처리\n",
    "- 우리의 말을 컴퓨터에게 이해시키기 위한 기술\n",
    "- 검색 엔진, 기계 번역, 질의응답 시스템, IME, 문장 자동요약, 감정 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시소러스\n",
    "- 단어의 의미를 사람이 정의하는 기법\n",
    "- thesaurus (유의어 사전) 을 활용하는 방법\n",
    "- 뜻이 비슷한 단어가 한 그룹으로 분류되어 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계 기반 기법\n",
    "- 말뭉치\n",
    "- 자연어 처리 연구나 애플리케이션을 염두에 두고 수집된 텍스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'you say goodbye and I say hello.'\n",
    "\n",
    "text = text.lower()\n",
    "\n",
    "word = text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "\n",
    "for idx, w in enumerate(word) :\n",
    "    word_to_idx[w] = idx\n",
    "    idx_to_word[idx] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'you': 0, 'say': 5, 'goodbye': 2, 'and': 3, 'i': 4, 'hello.': 6},\n",
       " {0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'say', 6: 'hello.'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx, idx_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text) :\n",
    "    text = text.lower()\n",
    "    #regx 로 문장 부호 분리 필요\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    word_to_idx = {}\n",
    "    idx_to_word = {}\n",
    "\n",
    "    for idx, w in enumerate(word) :\n",
    "        word_to_idx[w] = idx\n",
    "        idx_to_word[idx] = w\n",
    "        \n",
    "    corpus = np.array([word_to_idx[w] for i in words])\n",
    "    \n",
    "    return corpus, word_to_idx, idx_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어의 분산 표현\n",
    "\n",
    "- 단어의 의미를 정확하게 표현할 수 있는 벡터 표현\n",
    "- co-occurence matrix 를 만든다. (-> 주변 맥락(window) 를 통해 확인)\n",
    "- 분포 가설"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### distributional hypothesis (분포 가설)\n",
    "- words that are used and occur in the same contexts tend to purport similar meanings\n",
    "- a word is characterized by the company it keeps (1950s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([\n",
    "    [0, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 1, 0, 1, 1, 0],\n",
    "    [0, 1, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 1, 0]\n",
    "], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#해당 단어가 다른 단어의 window에 속한 횟수\n",
    "np.sum(C, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터 간 유사도\n",
    "- 코사인 유사도\n",
    "    - 분모는 L2 norm 제곱합의 제곱근(root)\n",
    "    - 분자는 벡터 간의 내적합\n",
    "- eps : 엡실론\n",
    "    - for division by zero error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps = 1e-8) :\n",
    "    nx = x / np.sqrt(np.sum(x**2)+eps)\n",
    "    ny = y / np.sqrt(np.sum(y**2)+eps)\n",
    "    \n",
    "    return np.dot(nx, xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most similar 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5) :\n",
    "    \n",
    "    if query not in word_to_id :\n",
    "        print(\"%s not found\" %query)\n",
    "        return\n",
    "\n",
    "    print('\\n[query] ' + query)\n",
    "    \n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    \n",
    "    for i in range(vocab_size) :\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "        \n",
    "    count = 0\n",
    "    \n",
    "    for i in (-1 * similarity).argsort() :\n",
    "        if id_to_word[i] == query :\n",
    "            continue\n",
    "        \n",
    "        print(\" %s : %s\" %(id_to_word[i], similarity[i]))\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count >= top :\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 통계 기반 기법 개선하기\n",
    "#### 상호정보량\n",
    "  - 단순 동시 발생 빈도수로 벡터를 만들면 고빈도 단어(관사와 같은) 는 모든 단어와 관련성이 높게 나타난다.\n",
    "  - 따라서 PMI 라는 지수를 활용해 벡터를 만든다.\n",
    "  - $$ PMI(x, y) = log_2 \\cfrac{C(x, y)*N}{C(x)C(y)} $$\n",
    "  - 양의 상호정보량 $$ PPMI(x, y) = max(0, PMI(x, y)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose = False, eps = 1e-8) :\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis = 0)\n",
    "    \n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(C.shape[0]) :\n",
    "        for j in range(C.shape[1]) :\n",
    "            pmi = np.log2(C[i, j] * N / (S[i]*S[j])+eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "            \n",
    "            if verbose :\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0 :\n",
    "                    print('%.1f%% 완료' % (100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문제 존재. : 단어마다 고유 인덱스. 단어의 수가 많을수록 행렬의 크기도 커진다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특이값 분해 (singular value decomposition)\n",
    "- 차원 축소를 위한 방법\n",
    "- u 직교 행렬(단어 공간의 기저) / s 특이값을 대각성분으로 한 대각행렬\n",
    "- u 와 v는 직교함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, v = np.linalg.svd(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00000000e+00, -3.63987887e-01,  7.77156117e-16,\n",
       "         -1.97083658e-01,  2.22044605e-16, -9.10313600e-01,\n",
       "          4.86171902e-17],\n",
       "        [ 8.46041188e-01,  0.00000000e+00,  2.26091196e-01,\n",
       "          0.00000000e+00, -4.82801284e-01,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [-4.48640785e-17, -5.77929845e-01,  8.30926981e-16,\n",
       "          3.79210349e-01,  3.10497138e-16,  1.48985251e-01,\n",
       "         -7.07106781e-01],\n",
       "        [ 4.97279485e-01, -7.65004295e-16, -6.61115197e-01,\n",
       "         -1.29942762e-16,  5.61818307e-01, -7.46273025e-17,\n",
       "          1.54500638e-17],\n",
       "        [-4.54404361e-17, -5.77929845e-01,  8.41601691e-16,\n",
       "          3.79210349e-01,  3.14486016e-16,  1.48985251e-01,\n",
       "          7.07106781e-01],\n",
       "        [-4.54404361e-17, -4.46662072e-01,  8.41601691e-16,\n",
       "         -8.20705217e-01,  3.14486016e-16,  3.56280704e-01,\n",
       "          2.14358315e-18],\n",
       "        [ 1.92165093e-01,  1.47712142e-15,  7.15408601e-01,\n",
       "          2.12584375e-16,  6.71761200e-01,  2.40242105e-16,\n",
       "         -3.09001277e-17]]),\n",
       " array([2.32436633e+00, 2.32436633e+00, 1.14718388e+00, 1.14718388e+00,\n",
       "        5.30368089e-01, 5.30368089e-01, 5.15650165e-17]),\n",
       " array([[ 3.63987887e-01, -1.11022302e-16,  5.77929845e-01,\n",
       "         -0.00000000e+00,  5.77929845e-01,  4.46662072e-01,\n",
       "          0.00000000e+00],\n",
       "        [ 0.00000000e+00, -8.46041188e-01, -3.57504178e-16,\n",
       "         -4.97279485e-01, -1.90970725e-16,  9.74763451e-16,\n",
       "         -1.92165093e-01],\n",
       "        [ 1.97083658e-01,  8.88178420e-16, -3.79210349e-01,\n",
       "          0.00000000e+00, -3.79210349e-01,  8.20705217e-01,\n",
       "          0.00000000e+00],\n",
       "        [ 0.00000000e+00, -2.26091196e-01,  5.78918738e-17,\n",
       "          6.61115197e-01, -2.47419458e-16,  2.52180903e-16,\n",
       "         -7.15408601e-01],\n",
       "        [-9.10313600e-01,  1.66533454e-16,  1.48985251e-01,\n",
       "          0.00000000e+00,  1.48985251e-01,  3.56280704e-01,\n",
       "          0.00000000e+00],\n",
       "        [-0.00000000e+00, -4.82801284e-01,  3.07446502e-17,\n",
       "          5.61818307e-01, -3.57833408e-16,  5.85856162e-16,\n",
       "          6.71761200e-01],\n",
       "        [-0.00000000e+00, -4.11740079e-17,  7.07106781e-01,\n",
       "         -3.93075594e-17, -7.07106781e-01, -6.82453687e-17,\n",
       "          3.32332789e-17]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, s, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 차원 축소\n",
    "- s 특이값이 큰 값만 살려도 되지 않을까? n번째 큰값으로만 해당 행렬을 복원해낼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 4, 3, 2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = ppmi(C)\n",
    "\n",
    "#SVD\n",
    "U, S, V = np.linalg.svd(W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
